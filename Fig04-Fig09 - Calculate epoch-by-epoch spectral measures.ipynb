{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy.signal as sig\n",
    "import scipy.stats as stat\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import h5py\n",
    "import resin\n",
    "import pandas as pd\n",
    "#import bark  # need to load Bird 4LL data\n",
    "\n",
    "from pandas import DataFrame,Series,read_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savePlots = False    # whether or not to save plots\n",
    "saveData = False     # whether or not to save csv files\n",
    "\n",
    "saveAsPath = './Epoch-by-epoch_variables/'\n",
    "if not os.path.exists(saveAsPath):\n",
    "    os.mkdir(saveAsPath)\n",
    "saveAsName = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "birdPaths =    ['../data_copies/01_PreprocessedData/01_BudgieFemale_green1/00_Baseline_night/',\n",
    "                '../data_copies/01_PreprocessedData/02_BudgieMale_yellow1/00_Baseline_night/',\n",
    "                '../data_copies/01_PreprocessedData/03_BudgieFemale_white1/00_Baseline_night/',\n",
    "                '../data_copies/01_PreprocessedData/04_BudgieMale_yellow2/00_Baseline_night/',\n",
    "                '../data_copies/01_PreprocessedData/05_BudgieFemale_green2/00_Baseline_night/']\n",
    "\n",
    "arfFilePaths =  ['EEG 2 scored/',\n",
    "                 'EEG 3 scored/',\n",
    "                 'EEG 3 scored/',\n",
    "                 'EEG 4 scored/',\n",
    "                 'EEG 4 scored/']\n",
    "\n",
    "### load BEST EEG channels - as determined during manual scoring ####\n",
    "channelsToLoadEEG_best = [['5 LEEGf-LEEGp', '6 LEEGm-LEEGp'],\n",
    "                     ['5 LEEGf-LEEGm', '4 LEEGf-Fgr'],\n",
    "                     ['4LEEGf-LEEGp', '9REEGm-REEGp'],\n",
    "                     ['9REEGf-REEGp', '6LEEGm-LEEGf'],\n",
    "                     ['4LEEGf-LEEGp','7REEGf-REEGp']]\n",
    "\n",
    "\n",
    "### load ALL of EEG channels ####\n",
    "channelsToLoadEEG = [['4 LEEGf-Fgr', '5 LEEGf-LEEGp', '6 LEEGm-LEEGp', '7 LEEGp-Fgr', '8 REEGp-Fgr','9 REEGp-LEEGp'],\n",
    "                     ['4 LEEGf-Fgr','5 LEEGf-LEEGm', '6 LEEGm-LEEGp', '7 REEGf-Fgr', '8 REEGm-Fgr', '9 REEGf-REEGm'],\n",
    "                     ['4LEEGf-LEEGp', '5LEEGf-LEEGm', '6LEEGm-LEEGp', '7REEGf-REEGp', '8REEGf-REEGm', '9REEGm-REEGp'],\n",
    "                     ['4LEEGf-LEEGp', '5LEEGm-LEEGp', '6LEEGm-LEEGf', '7REEGf-Fgr', '8REEGf-REEGm','9REEGf-REEGp',],\n",
    "                     ['4LEEGf-LEEGp', '5LEEGf-LEEGm', '6LEEGm-LEEGp', '7REEGf-REEGp', '8REEGf-REEGm', '9REEGm-REEGp']]\n",
    "\n",
    "\n",
    "channelsToLoadEOG = [['1 LEOG-Fgr', '2 REOG-Fgr'],\n",
    "                     ['2 LEOG-Fgr', '3 REOG-Fgr'],\n",
    "                     ['2LEOG-Fgr', '3REOG-Fgr'],\n",
    "                     ['2LEOG-Fgr', '3REOG-Fgr'],\n",
    "                     ['2LEOG-Fgr', '3REOG-Fgr']]\n",
    "\n",
    "birds_LL = [1,2,3]\n",
    "nBirds_LL = len(birds_LL)\n",
    "\n",
    "birdPaths_LL = ['../data_copies/01_PreprocessedData/02_BudgieMale_yellow1/01_Constant_light/',\n",
    "                '../data_copies/01_PreprocessedData/03_BudgieFemale_white1/01_Constant_light/',\n",
    "                '../data_copies/01_PreprocessedData/04_BudgieMale_yellow2/01_Constant_light/',]\n",
    "\n",
    "arfFilePaths_LL =  ['EEG 2 preprocessed/',\n",
    "                    'EEG 2 preprocessed/',\n",
    "                    'EEG 2 preprocessed/']\n",
    "\n",
    "lightsOffSec = np.array([7947, 9675, 9861 + 8*3600, 9873, 13467])  # lights off times in seconds from beginning of file\n",
    "lightsOnSec = np.array([46449, 48168, 48375+ 8*3600, 48381, 52005]) # Bird 3 gets 8 hours added b/c file starts at 8:00 instead of 16:00\n",
    "\n",
    "epochLength = 3\n",
    "sr = 200\n",
    "scalingFactor = (2**15)*0.195       # scaling/conversion factor from amplitude to uV (when recording arf from jrecord)\n",
    "\n",
    "stages = ['w','d','u','i','s','r'] # wake, drowsy, unihem sleep, intermediate sleep, SWS, REM\n",
    "stagesSleep =    ['u','i','s','r']\n",
    "\n",
    "stagesVideo = ['m','q','d','s','u'] # moving wake, quiet wake, drowsy, sleep, unclear\n",
    "\n",
    "## Path to scores formatted as CSVs\n",
    "formatted_scores_path = '../formatted_scores/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = sns.color_palette(np.array([[234,103,99],\n",
    "[218,142,60],\n",
    "[174,174,62],\n",
    "[97,188,101],\n",
    "[140,133,232],\n",
    "[225,113,190]])\n",
    "/255)\n",
    "\n",
    "sns.palplot(colors)\n",
    "\n",
    "# colorpalette from iWantHue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot-specific info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"notebook\", font_scale=1.5)\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "# Markers for legends of EEG scoring colors\n",
    "legendMarkersEEG = []\n",
    "for stage in range(len(stages)):\n",
    "    legendMarkersEEG.append(plt.Line2D([0],[0], color=colors[stage], marker='o', linestyle='', alpha=0.7))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate general variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightsOffEp = lightsOffSec / epochLength\n",
    "lightsOnEp = lightsOnSec / epochLength\n",
    "\n",
    "nBirds = len(birdPaths)\n",
    "\n",
    "epochLengthPts = epochLength*sr\n",
    "\n",
    "nStages = len(stagesSleep)\n",
    "\n",
    "#birds = ['1', '2', '3', '4', '5', '2LL']\n",
    "birds = ['1', '2', '3', '4', '5', '2LL', '3LL', '4LL'] # import LL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in EEG files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEGdataAll = {}\n",
    "TimeIndexEEG = {}\n",
    "TimeIndexPower = {}\n",
    "\n",
    "for b_num in birds: \n",
    "    \n",
    "    b = int(b_num[0]) - 1   \n",
    "        \n",
    "##### arf files for all datasets except 4LL\n",
    "    \n",
    "    if '4LL' not in b_num:\n",
    "    \n",
    "        if 'LL' in b_num:\n",
    "            arf_path = birdPaths_LL[b-1] + arfFilePaths_LL[b-1]\n",
    "        else:\n",
    "            arf_path = birdPaths[b] + arfFilePaths[b]\n",
    "\n",
    "        for channel in channelsToLoadEEG[b]:\n",
    "            all_data_array = np.array([])\n",
    "\n",
    "            for file in np.sort(os.listdir(arf_path)):\n",
    "                if file.endswith('.arf'):\n",
    "                    arffile = h5py.File(arf_path+file, 'r')\n",
    "                    data_array = arffile['.'][channel][()]\n",
    "                    data_array = np.ndarray.flatten(data_array)\n",
    "\n",
    "                    # Pad the end with NaN's to make it divisible by epoch length\n",
    "                    nanPadding = np.zeros(epochLengthPts - np.mod(len(data_array), epochLengthPts))\n",
    "                    nanPadding.fill(np.nan)\n",
    "                    data_array = np.append(data_array,nanPadding)   \n",
    "\n",
    "                    all_data_array = np.append(all_data_array,data_array)\n",
    "\n",
    "            # Do not reshape\n",
    "\n",
    "            # Save in dict under bird number and channel\n",
    "            data_name = 'Bird ' + b_num + ': ' + channel\n",
    "            EEGdataAll[data_name] = scalingFactor * all_data_array\n",
    "    \n",
    "##### bark files for 4LL\n",
    "\n",
    "    elif '4LL' in b_num:\n",
    "        if 'LL' in b_num:\n",
    "            arf_path = birdPaths_LL[b-1] + arfFilePaths_LL[b-1]\n",
    "        else:\n",
    "            arf_path = birdPaths[b] + arfFilePaths[b]\n",
    "        \n",
    "        for channel in channelsToLoadEEG[b]:\n",
    "            all_data_array = np.array([])\n",
    "\n",
    "            for file in np.sort(os.listdir(arf_path)):\n",
    "                if file.endswith('.dat'):\n",
    "                    dset = bark.read_sampled(arf_path + file)\n",
    "\n",
    "                    # get channel number\n",
    "                    ch_num = [x for x in dset.attrs['columns'].keys() if channel in dset.attrs['columns'][x]['channel_name']]\n",
    "                    if len(ch_num) != 1:\n",
    "                        print(\"for bird\", b_num, \"channel\", channel, \": correct number of channels not found\")\n",
    "\n",
    "                    data_array = dset.data[:, ch_num]\n",
    "                    data_array = np.array(np.ndarray.flatten(data_array))  # flatten and take out of memmap modes\n",
    "\n",
    "                    # Pad the end with NaN's to make it divisible by epoch length\n",
    "                    nanPadding = np.zeros(epochLengthPts - np.mod(len(data_array), epochLengthPts))\n",
    "                    nanPadding.fill(np.nan)\n",
    "                    data_array = np.append(data_array,nanPadding)   \n",
    "\n",
    "                    all_data_array = np.append(all_data_array,data_array)\n",
    "\n",
    "                # Do not reshape\n",
    "\n",
    "                # Save in dict under bird number and channel\n",
    "                data_name = 'Bird ' + b_num + ': ' + channel\n",
    "                EEGdataAll[data_name] = scalingFactor * all_data_array\n",
    "    \n",
    "##### Create time index for EEG\n",
    "\n",
    "    all_time_array = np.array([], dtype='datetime64')\n",
    "    for file in np.sort(os.listdir(arf_path)):\n",
    "        if file.endswith('.arf')|file.endswith('.dat'):\n",
    "\n",
    "            date = file.split('_')[2]\n",
    "\n",
    "            if (b == 0) & ('2014-10-17' in file):\n",
    "                hours = '17'\n",
    "                minutes = '32'\n",
    "            elif b == 0:\n",
    "                hours = '09'\n",
    "                minutes = '00'\n",
    "            else:\n",
    "                time = file.split('_')[3].split('.')[0]\n",
    "                hours = time.split('-')[0]\n",
    "                minutes = time.split('-')[1]\n",
    "\n",
    "            datetime_start = np.datetime64(date + 'T' + hours + ':' + minutes + ':06')    # assume 6-s delay in starting recording\n",
    "\n",
    "            # time index in datetime format\n",
    "            \n",
    "            if file.endswith('.arf'):\n",
    "                arffile = h5py.File(arf_path+file, 'r')\n",
    "                length_pts   = len(arffile['.'][channel][()])\n",
    "            elif file.endswith('.dat'):\n",
    "                length_pts   = len(bark.read_sampled(arf_path + file).data[:,0])\n",
    "            \n",
    "            padding_pts = epochLengthPts - np.mod(length_pts, epochLengthPts)\n",
    "            length_s = (length_pts+padding_pts)/sr\n",
    "            length_ms = np.timedelta64(int(1000 * length_s), 'ms')\n",
    "            datetime_end = datetime_start + length_ms\n",
    "\n",
    "            time_array = np.arange(datetime_start, datetime_end, np.timedelta64(int(1000/sr),'ms')) \n",
    "\n",
    "            # Add to end of whole-night time index\n",
    "            all_time_array = np.append(all_time_array, time_array)\n",
    "\n",
    "\n",
    "    data_name = 'Bird ' + b_num\n",
    "    TimeIndexEEG[data_name] = all_time_array\n",
    "    \n",
    "    # Get time at the start of each epoch\n",
    "    TimeIndexPower[data_name] = all_time_array[np.arange(0,len(all_time_array),epochLengthPts)]\n",
    "    \n",
    "\n",
    "EEGchannels = np.sort(list(EEGdataAll.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load formatted scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring scores into alignment with padded EEGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllScores = {}\n",
    "for b in birds:\n",
    "    # Load from file\n",
    "    scores_file = 'All_scores_Bird {}.csv'.format(b)\n",
    "    tmp_scores = pd.read_table(formatted_scores_path + scores_file, sep=',', index_col=0)\n",
    "\n",
    "    # Reindex according to TimeIndexPower for that bird\n",
    "    tmp_time_index = TimeIndexPower['Bird ' + str(b)]\n",
    "    tmp_scores = tmp_scores.reindex(pd.to_datetime(tmp_scores.index)) # convert original index to pandas datetimes\n",
    "    tmp_scores = tmp_scores[~tmp_scores.index.duplicated()] # remove any duplicates\n",
    "    reindexed_scores = tmp_scores.reindex(pd.to_datetime(tmp_time_index)) # reindex with EEG-based index\n",
    "    \n",
    "    # save to dict\n",
    "    AllScores['Bird ' + str(b)] = reindexed_scores    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate lights off in Zeitgeber time (s and hrs)\n",
    "Lights on is 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightsOffDatetime = np.array([], dtype='datetime64')\n",
    "lightsOnDatetime = np.array([], dtype='datetime64')\n",
    "\n",
    "for b_num in range(nBirds):\n",
    "    b_name = 'Bird ' + str(b_num+1)\n",
    "    Scores = AllScores[b_name]\n",
    "    startDatetime = np.datetime64(Scores.index.values[0])\n",
    "\n",
    "    # Calc lights off & on using datetime formats\n",
    "    lightsOffTimedelta = lightsOffSec[b_num].astype('timedelta64[s]')\n",
    "    lightsOffDatetime = np.append(lightsOffDatetime, startDatetime + lightsOffTimedelta)\n",
    "    lightsOnTimedelta = lightsOnSec[b_num].astype('timedelta64[s]')\n",
    "    lightsOnDatetime = np.append(lightsOnDatetime, startDatetime + lightsOnTimedelta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightsOffZeit_s = lightsOffSec - lightsOnSec\n",
    "lightsOffZeit_hr = lightsOffZeit_s / 3600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mark artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert score labels to numbers: \n",
    "* mark any 'moving' video-labels as -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bird in birds:\n",
    "    bird = 'Bird ' + b\n",
    "    Scores = AllScores[bird]\n",
    "    # replace nan's with empty string\n",
    "    Scores.fillna('', inplace=True)\n",
    "    \n",
    "    if \"LL\" not in b:\n",
    "\n",
    "        Label_num = -1 * np.ones_like(Scores['Label'])\n",
    "        for st in range(len(stages)):\n",
    "            stage_inds = [x for x in range(len(Scores['Label'])) if stages[st] in Scores['Label'].iloc[x]]\n",
    "            Label_num[stage_inds] = st\n",
    "\n",
    "        # Moving labels\n",
    "        stage_video_inds = [x for x in range(len(Scores['Label'])) if ('m' in Scores['Video Label'].iloc[x])]\n",
    "        Label_num[stage_video_inds] = -1\n",
    "\n",
    "        # Save to dataframe\n",
    "        AllScores[bird]['Label (#)'] = Label_num\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for each channel, mark as artifact epochs w/ data that crosses an amplitude threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set thresholds\n",
    "#artifact_threshold_uV = 400\n",
    "artifact_threshold_SD  = 6   # of SDs away from mean\n",
    "\n",
    "# Make a scores array for each channel so it has independent artifact removal\n",
    "ChannelScores = {}\n",
    "\n",
    "for ch in EEGchannels:\n",
    "    data = EEGdataAll[ch]\n",
    "    # mean + N*SD\n",
    "    artifact_threshold_SD_uV = (data[~np.isnan(data)]).mean() + artifact_threshold_SD*(data[~np.isnan(data)]).std()\n",
    "    print(ch + ' : ' + str(artifact_threshold_SD_uV))\n",
    "    \n",
    "    #artifact_threshold = np.max([artifact_threshold_uV, artifact_threshold_SD_uV])\n",
    "    artifact_threshold = artifact_threshold_SD_uV\n",
    "        \n",
    "    b_name = ch[0:6]\n",
    "    bird_scores = np.array(AllScores[b_name]['Label (#)'].values)   # get scores as an array of numbers\n",
    "    nEpochs = len(bird_scores)\n",
    "\n",
    "    for ep in range(nEpochs):\n",
    "        start_pts = ep * epochLengthPts\n",
    "        stop_pts  = (ep+1) * epochLengthPts\n",
    "        \n",
    "        ep_data = data[start_pts:stop_pts]\n",
    "        \n",
    "        if any(np.abs(ep_data) > artifact_threshold):\n",
    "            bird_scores[ep] = -2\n",
    "            \n",
    "    # Save to dataframe\n",
    "    ChannelScores[ch] = bird_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load_EM_artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_EM_artifacts(b):\n",
    "    birdPath = '0{}_Bird_{}_SW_EM_detected/'.format(b,b)\n",
    "    path = events_path + birdPath\n",
    "\n",
    "    all_ch_data = {}   # init\n",
    "\n",
    "    for file in os.listdir(path):\n",
    "        if 'EMartifacts' in file:\n",
    "            # Get channel\n",
    "            ch_tmp = file.split('_')[-1]\n",
    "            ch = ch_tmp.split('.')[0]\n",
    "            ch_data = pd.read_table(path+file, sep=',', index_col=0)\n",
    "\n",
    "            if ch in all_ch_data.keys():\n",
    "                all_ch_data[ch] = all_ch_data[ch].append(ch_data)\n",
    "            else:\n",
    "                all_ch_data[ch] = ch_data\n",
    "\n",
    "    channel_names = list(all_ch_data.keys())\n",
    "    \n",
    "    return(all_ch_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## assign_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_epoch(data):\n",
    "    '''data: a single Dataframe (eg, for SWs, must provide all_ch_data[ch])'''\n",
    "\n",
    "    epochID = np.floor(data['Start'] / epochLength)\n",
    "    data['Epoch # start'] = epochID\n",
    "    data['Epoch #'] = epochID\n",
    "    epochID = np.floor(data['Stop'] / epochLength)\n",
    "    data['Epoch # stop'] = epochID\n",
    "    data['Length'] = data['Stop'] - data['Start']\n",
    "    \n",
    "    # Detect & split overlaps (ie events spanning more than one epoch)\n",
    "    overlaps = data[data['Epoch # start'] != data['Epoch # stop']]\n",
    "    non_overlaps_tmp = data[data['Epoch # start'] == data['Epoch # stop']]\n",
    "    non_overlaps = non_overlaps_tmp[['Label', 'Epoch #', 'Start', 'Stop', 'Length']]\n",
    "\n",
    "    # Dataframe for first half of event\n",
    "    overlaps_first_ep = pd.DataFrame(overlaps[['Label', 'Epoch #', 'Start']])\n",
    "    overlaps_first_ep['Stop'] = epochLength * overlaps['Epoch # stop'].values\n",
    "    overlaps_first_ep['Length'] = overlaps_first_ep['Stop'] - overlaps_first_ep['Start']\n",
    "\n",
    "    # Dataframe for second half of event\n",
    "    overlaps_second_ep = pd.DataFrame(overlaps[['Label']])\n",
    "    overlaps_second_ep['Epoch #'] = overlaps['Epoch # stop'].values\n",
    "    overlaps_second_ep['Start'] = epochLength * overlaps['Epoch # stop'].values\n",
    "    overlaps_second_ep['Stop'] = overlaps['Stop'].values\n",
    "    overlaps_second_ep['Length'] = overlaps_second_ep['Stop'] - overlaps_second_ep['Start']\n",
    "\n",
    "    # Concatenate non-overlaps with the split events\n",
    "    data = pd.concat([overlaps_first_ep, overlaps_second_ep, non_overlaps], ignore_index=True)\n",
    "    data = data.sort_values(by='Start')\n",
    "    data = data.reset_index(drop=True)\n",
    "    \n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EMartifacts = {}\n",
    "\n",
    "for b in birds:\n",
    "\n",
    "    tmp_bird_EMartifacts = load_EM_artifacts(b)\n",
    "    channels = tmp_bird_EMartifacts.keys()\n",
    "    for ch in channels:\n",
    "\n",
    "        data = assign_epoch(tmp_bird_EMartifacts[ch])\n",
    "        Artifact_sec_per_epoch = data.groupby(['Epoch #'])['Length'].sum() ## currently using this one\n",
    "        Artifact_max_duration_per_epoch = data.groupby(['Epoch #'])['Length'].max()\n",
    "\n",
    "        ch_name = 'Bird ' + str(b) + ': ' + ch\n",
    "        EMartifacts[ch_name] = Artifact_sec_per_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For each bird find epochs with too much EM artifact\n",
    "EM_artifact_thres = .5  # in seconds/epoch\n",
    "for ch in EEGchannels:\n",
    "\n",
    "    bird = int(ch[5])-1\n",
    "    bird_name = \"Bird \" + ch[5]\n",
    "\n",
    "    # Get EM artifact data for that channel\n",
    "    tmp_data = EMartifacts[ch]\n",
    "    tmp_data = tmp_data.reindex(AllScores[bird_name]['Epoch #'])\n",
    "    \n",
    "\n",
    "    too_many_artifacts = tmp_data > EM_artifact_thres\n",
    "\n",
    "    ch_scores = np.array(ChannelScores[ch])\n",
    "    inds_artifacts = np.where(too_many_artifacts)[0]\n",
    "    print(ch + \": \" + str(len(inds_artifacts)) + \" epochs removed\")\n",
    "    print(pd.Series(ch_scores[inds_artifacts]).value_counts())\n",
    "    ch_scores[inds_artifacts] = -3\n",
    "\n",
    "    # Save to dataframe\n",
    "    ChannelScores[ch] = ch_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllScores['Bird 1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get variables for each 1-s \"epoch\" of sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral total power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SleepVariables = {}\n",
    "\n",
    "# set epoch length for spectral analysis\n",
    "epochLength_analysis = 1\n",
    "epochLengthPts_analysis = sr*epochLength_analysis\n",
    "\n",
    "for ch in EEGchannels:\n",
    "    \n",
    "    b_name = ch.split(':')[0]\n",
    "    # load data\n",
    "    rawdata = np.ndarray.flatten(EEGdataAll[ch])\n",
    "    # number of analysis epochs\n",
    "    nEpochs = int(len(rawdata)/epochLengthPts_analysis)\n",
    "    \n",
    "    # initialize\n",
    "    ch_Delta = np.zeros(nEpochs)\n",
    "    ch_Gamma = np.zeros(nEpochs)\n",
    "    ch_GammaDeltaRatio = np.zeros(nEpochs)\n",
    "    ch_Delta.fill(np.nan)\n",
    "    ch_Gamma.fill(np.nan)\n",
    "    ch_GammaDeltaRatio.fill(np.nan)\n",
    "\n",
    "    # 1. Get multitaper power spectrum: 3s epochs with sliding 1-s window\n",
    "    \n",
    "    spec = resin.Spectra(rate=sr, \n",
    "        NFFT=epochLengthPts,\n",
    "        data_window=epochLengthPts,\n",
    "        noverlap=2*epochLengthPts_analysis,  ## 1-s overlap on either side of window\n",
    "        n_tapers=2,   # 2 tapers not 4\n",
    "        NW = 3,\n",
    "        freq_range=(0, 60))\n",
    "    spec.signal(rawdata)\n",
    "\n",
    "    epPower = spec.power()[0]\n",
    "    epFFTfreqs = spec.power()[1]\n",
    "        \n",
    "    # 1a. Save delta and gamma bands\n",
    "    \n",
    "    ##### EDITED: DELTA SPECTRUM to match Low et al paper (1 - 4 Hz instead of 0.5 - 4 Hz)\n",
    "    indsDelta = np.where((epFFTfreqs >= 1)   & (epFFTfreqs <= 4))\n",
    "    indsGamma = np.where((epFFTfreqs >= 30)  & (epFFTfreqs <= 55))\n",
    "    \n",
    "    ch_Delta = np.sum(epPower[indsDelta], axis=0)\n",
    "    ch_Gamma = np.sum(epPower[indsGamma], axis=0)\n",
    "    ch_GammaDeltaRatio = ch_Gamma/ch_Delta\n",
    "\n",
    "    \n",
    "    # 2a. Log of delta\n",
    "    ch_DeltaLog = np.log10(ch_Delta)\n",
    "        \n",
    "    # 3. Get sleep scores: each 1s epoch gets the score of the entire 3-s epoch it's in\n",
    "    ### USE ORIGINAL SCORES rather than artifact-removed scores for each channel\n",
    "    bird_video_scores = np.repeat(AllScores[b_name]['Video Label'].values, 3, axis=0)\n",
    "    \n",
    "    #\n",
    "    if 'LL' in ch:\n",
    "        is_sleep = bird_video_scores == 's'\n",
    "    else: ## only have PSG scores for LD datasets\n",
    "        bird_scores = np.repeat(AllScores[b_name]['Label (#)'].values, 3, axis=0)\n",
    "        is_sleep = bird_scores > 2\n",
    "    \n",
    "    # epoch ID\n",
    "    epochs_3s = np.repeat(AllScores[b_name]['Epoch #'].values, 3, axis=0)\n",
    "    \n",
    "    # 4. Save to dataframe\n",
    "    sleep_variables = DataFrame([])\n",
    "    sleep_variables[\"Delta\"] = ch_Delta\n",
    "    sleep_variables[\"DeltaLog\"] = ch_DeltaLog\n",
    "    sleep_variables[\"GammaDeltaRatio\"] = ch_GammaDeltaRatio\n",
    "    sleep_variables[\"video scores\"] = bird_video_scores\n",
    "    sleep_variables[\"is sleep\"] = is_sleep\n",
    "    sleep_variables[\"Epoch\"] = epochs_3s[0:len(bird_video_scores)]\n",
    "    \n",
    "    if 'LL' not in ch:\n",
    "        sleep_variables[\"sleep scores\"] = bird_scores\n",
    "\n",
    "    SleepVariables[ch] = sleep_variables\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "for ch in EEGchannels:\n",
    "    \n",
    "    b_name = ch.split(':')[0]\n",
    "    # load data\n",
    "    rawdata = np.ndarray.flatten(EEGdataAll[ch])\n",
    "    # number of analysis epochs\n",
    "    nEpochs = int(len(rawdata)/epochLengthPts_analysis)\n",
    "    \n",
    "    sleep_variables = SleepVariables[ch].copy()\n",
    "    \n",
    "    # 1. Calculate gradients of delta & gamma/delta\n",
    "                #ch_gradientDelta = np.gradient(ch_Delta)\n",
    "                #ch_gradientDeltaLog = np.gradient(ch_DeltaLog)\n",
    "                #ch_gradientGammaDelta = np.gradient(ch_GammaDeltaRatio)\n",
    "    \n",
    "    # 2. Drop non-sleep epochs\n",
    "    sleep_variables = sleep_variables[sleep_variables['is sleep']]\n",
    "    \n",
    "    ch_Delta = sleep_variables['Delta']\n",
    "    ch_DeltaLog = sleep_variables['DeltaLog']\n",
    "    ch_GammaDeltaRatio = sleep_variables['GammaDeltaRatio']\n",
    "    \n",
    "    # 3.  Get time points\n",
    "    dt = sleep_variables.index.values\n",
    "    \n",
    "    # 4.  Calculate gradients of delta & gamma/delta\n",
    "    ch_gradientDelta = np.gradient(ch_Delta, dt)\n",
    "    ch_gradientDeltaLog = np.gradient(ch_DeltaLog, dt)\n",
    "    ch_gradientGammaDelta = np.gradient(ch_GammaDeltaRatio, dt)\n",
    "    \n",
    "    \n",
    "    # 5. Save to dataframe\n",
    "    sleep_variables[\"diffDelta\"] = ch_gradientDelta\n",
    "    sleep_variables[\"diffDeltaLog\"] = ch_gradientDeltaLog\n",
    "    sleep_variables[\"diffGammaDeltaRatio\"] = ch_gradientGammaDelta\n",
    "    \n",
    "    SleepVariables[ch] = sleep_variables\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SDs, nPeaks, and max amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "\n",
    "for ch in EEGchannels:\n",
    "\n",
    "    b_name = ch.split(':')[0]\n",
    "    # load data\n",
    "    rawdata = np.ndarray.flatten(EEGdataAll[ch])\n",
    "    # number of analysis epochs\n",
    "    nEpochs = int(len(rawdata)/epochLengthPts_analysis)\n",
    "    \n",
    "    sleep_variables = SleepVariables[ch].copy()\n",
    "\n",
    "    # 1. Reshape data so 1 row = 1 epoch ####\n",
    "    all_data_array = np.reshape(rawdata, (nEpochs, epochLengthPts_analysis))\n",
    "    \n",
    "    # 2. Init MAX AMPLITUDE PER 3-s EPOCH\n",
    "    nSleepEpochs = len(sleep_variables)\n",
    "    ch_max_amp = np.zeros(nEpochs)\n",
    "    ch_max_amp.fill(np.nan)\n",
    "\n",
    "    # 3. Init nPeaks per 3-s epoch\n",
    "    \n",
    "    ch_nPeaks = np.zeros(nEpochs)\n",
    "    ch_nPeaks.fill(np.nan)\n",
    "    \n",
    "    # 4. Init SD of waveform FOR 3-S EPOCH --- including wake etc\n",
    "    ch_waveformSD = np.zeros(nEpochs)\n",
    "    ch_waveformSD.fill(np.nan)\n",
    "\n",
    "    for ep in sleep_variables.index:\n",
    "        #### Construct the 3-s windows sliding by 1s\n",
    "        \n",
    "        # first epoch\n",
    "        if ep == 0:\n",
    "            tmp_3s_window = np.concatenate([all_data_array[ep], all_data_array[ep+1]])\n",
    "\n",
    "        # last epoch\n",
    "        elif ep == nEpochs-1:\n",
    "            tmp_3s_window = np.concatenate([all_data_array[ep-1], all_data_array[ep]])\n",
    "\n",
    "        # normal epochs\n",
    "        else:\n",
    "            tmp_3s_window = np.concatenate([all_data_array[ep-1], all_data_array[ep], all_data_array[ep+1]])\n",
    "\n",
    "        #### Calculate per-epoch variables\n",
    "            \n",
    "        # max amp\n",
    "        ch_max_amp[ep] = np.max(np.abs(tmp_3s_window))\n",
    "            \n",
    "        # nPeaks\n",
    "        peaks = sig.argrelmax(tmp_3s_window)\n",
    "        ch_nPeaks[ep] = len(peaks[0])\n",
    "            \n",
    "        # SD\n",
    "        ch_waveformSD[ep] = np.std(tmp_3s_window)\n",
    "        \n",
    "                \n",
    "    # 5. take only sleep epochs\n",
    "    ch_max_amp = ch_max_amp[sleep_variables.index]\n",
    "    ch_nPeaks = ch_nPeaks[sleep_variables.index]\n",
    "    ch_waveformSD = ch_waveformSD[sleep_variables.index]\n",
    "        \n",
    "    # don't z-score variables yet, because this will include wake episodes with lots of artifact\n",
    "    \n",
    "    # 6. Save to dataframe\n",
    "    sleep_variables[\"max amp\"] = ch_max_amp\n",
    "    sleep_variables[\"SD\"] = ch_waveformSD\n",
    "    sleep_variables[\"nPeaks\"] = ch_nPeaks\n",
    "\n",
    "    \n",
    "    SleepVariables[ch] = sleep_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel in SleepVariables.keys():\n",
    "    data = SleepVariables[channel]\n",
    "    data.to_csv(saveAsPath + channel + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "298px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
